{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_VGGFace2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvek+mDMWBNsjMAmKuQaN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r0cketr1kky/PPML_Face_Rec/blob/master/ResNet_VGGFacenew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfQE7Z_q99RR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "5428b27c-fe25-4e84-d117-0d495c9d3c13"
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-2ffysnhp\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-2ffysnhp\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (7.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.2)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=e62797921d89ec6b106bb1973082e3fe45d27f309932e653371447f5fd662ef6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0la82jft/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1vOLDcM-CEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a10951c2-e4ad-488e-9a6d-c61b52388bbd"
      },
      "source": [
        "!pip show keras-vggface"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: keras-vggface\n",
            "Version: 0.6\n",
            "Summary: VGGFace implementation with Keras framework\n",
            "Home-page: https://github.com/rcmalli/keras-vggface\n",
            "Author: Refik Can MALLI\n",
            "Author-email: mallir@itu.edu.tr\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: h5py, keras, numpy, pyyaml, scipy, six, pillow\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEH798rq-OnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9e3ae48-b3c9-4e33-f2ca-ebf7d547711d"
      },
      "source": [
        "import keras_vggface"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkrwIzYQ-Ui2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "89d5b250-ad3a-4485-d287-5d2e08896370"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPV2Vb56_Rsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mtcnn"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHI1kjnVz1It",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c114eb9-b591-4181-cac8-cb889a3758bf"
      },
      "source": [
        "!pip install tf-encrypted"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-encrypted\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/be/a4c0af9fdc5e5cee28495460538acf2766382bd572e01d4847abc7608dba/tf_encrypted-0.5.9-py3-none-manylinux1_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 307kB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 4.0MB/s \n",
            "\u001b[?25hCollecting tensorflow<2,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/36/9a02e27f0ec248b676a380ffe910c1858e3af3027c0d4d513dd0b56a5613/tensorflow-1.15.3-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (3.12.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.30.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.12.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (3.2.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted) (49.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.12.0->tf-encrypted) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted) (3.1.0)\n",
            "Building wheels for collected packages: pyyaml, gast\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=bc39e41449d49e89a0a4e67c537d770c92dfa473bf44886bba6cf0b1edeae9ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=2a44e1b34556c9a2a2cb24e4e993fef501c0b4f96b70a9211a1ce246dc0eba24\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built pyyaml gast\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08lwcOO-z2xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMvhvFZS_tO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "30d3702e-df6b-4752-e59d-ee5dc8f00f2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jExmuXcJvEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "fpath = '/content/gdrive/My Drive/Face_images'\n",
        "\n",
        "f = os.listdir(fpath)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wITSfmW5WOsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3787877c-b1c4-4125-c866-db2189c0cef7"
      },
      "source": [
        "f"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arsene_Wenger.jpg',\n",
              " 'Channing_Tatum.jpg',\n",
              " 'Suzanne_Shaw.jpg',\n",
              " 'Joaquin_Phoenix.jpg',\n",
              " 'Alyson_Hannigan.jpg',\n",
              " 'David_Alaba.jpg',\n",
              " 'Brie_Larson.jpg',\n",
              " 'Sebastian_Vettel.jpg',\n",
              " 'Elizabeth_Olsen.jpg',\n",
              " 'Kajal_Aggarwal.jpg',\n",
              " 'testimages']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMntOZsWKFzy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "15f1f5db-21f7-4230-cfac-375d7474b0e4"
      },
      "source": [
        "f = f[:len(f)-1]\n",
        "f"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arsene_Wenger.jpg',\n",
              " 'Channing_Tatum.jpg',\n",
              " 'Suzanne_Shaw.jpg',\n",
              " 'Joaquin_Phoenix.jpg',\n",
              " 'Alyson_Hannigan.jpg',\n",
              " 'David_Alaba.jpg',\n",
              " 'Brie_Larson.jpg',\n",
              " 'Sebastian_Vettel.jpg',\n",
              " 'Elizabeth_Olsen.jpg',\n",
              " 'Kajal_Aggarwal.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-7NyrFdJpjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT2wTaeEYRke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a79303e2-ab9f-4723-f597-af226f6f6cce"
      },
      "source": [
        "for i in range(len(f)):\n",
        "  f[i] = '/content/gdrive/My Drive/Face_images/' + f[i]\n",
        "\n",
        "f"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/Face_images/Arsene_Wenger.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Channing_Tatum.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Suzanne_Shaw.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Joaquin_Phoenix.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Alyson_Hannigan.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/David_Alaba.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Brie_Larson.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Sebastian_Vettel.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Elizabeth_Olsen.jpg',\n",
              " '/content/gdrive/My Drive/Face_images/Kajal_Aggarwal.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlJxV0q3P6Ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "4b92fa3f-ff4d-44c5-ffd2-0dccd24fb0f2"
      },
      "source": [
        "'''VGGFace models for Keras.\n",
        "\n",
        "# Notes:\n",
        "- Resnet50 and VGG16  are modified architectures from Keras Application folder. [Keras](https://keras.io)\n",
        "\n",
        "- Squeeze and excitation block is taken from  [Squeeze and Excitation Networks in\n",
        " Keras](https://github.com/titu1994/keras-squeeze-excite-network) and modified.\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, \\\n",
        "    GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
        "    AveragePooling2D, Reshape, Permute, multiply\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from tensorflow.keras import backend as K\n",
        "from keras_vggface import utils\n",
        "from keras.engine.topology import get_source_inputs\n",
        "import warnings\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def VGG16(include_top=True, weights='vggface',\n",
        "          input_tensor=None, input_shape=None,\n",
        "          pooling=None,\n",
        "          classes=2622):\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=48,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "    \n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    \n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(\n",
        "        x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(\n",
        "        x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(\n",
        "        x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = Flatten(name='flatten')(x)\n",
        "        x = Dense(4096, name='fc6')(x)\n",
        "        x = Activation('relu', name='fc6/relu')(x)\n",
        "        x = Dense(4096, name='fc7')(x)\n",
        "        x = Activation('relu', name='fc7/relu')(x)\n",
        "        x = Dense(classes, name='fc8')(x)\n",
        "        x = Activation('softmax', name='fc8/softmax')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "            # Ensure that the model takes into account\n",
        "            # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "        # Create model.\n",
        "    model = Model(inputs, x, name='vggface_vgg16')  # load weights\n",
        "    if weights == 'vggface':\n",
        "        if include_top:\n",
        "            weights_path = get_file('rcmalli_vggface_tf_vgg16.h5',\n",
        "                                    utils.\n",
        "                                    VGG16_WEIGHTS_PATH,\n",
        "                                    cache_subdir=utils.VGGFACE_DIR)\n",
        "        else:\n",
        "            weights_path = get_file('rcmalli_vggface_tf_notop_vgg16.h5',\n",
        "                                    utils.VGG16_WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir=utils.VGGFACE_DIR)\n",
        "        model.load_weights(weights_path, by_name=True)\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            if include_top:\n",
        "                maxpool = model.get_layer(name='pool5')\n",
        "                shape = maxpool.output_shape[1:]\n",
        "                dense = model.get_layer(name='fc6')\n",
        "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
        "                                                              'channels_first')\n",
        "\n",
        "            if K.backend() == 'tensorflow':\n",
        "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_identity_block(input_tensor, kernel_size, filters, stage, block,\n",
        "                          bias=False):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
        "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
        "        block) + \"_1x1_increase\"\n",
        "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), use_bias=bias, name=conv1_reduce_name)(\n",
        "        input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, use_bias=bias,\n",
        "               padding='same', name=conv3_name)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), use_bias=bias, name=conv1_increase_name)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_conv_block(input_tensor, kernel_size, filters, stage, block,\n",
        "                      strides=(2, 2), bias=False):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
        "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
        "        block) + \"_1x1_increase\"\n",
        "    conv1_proj_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\n",
        "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides, use_bias=bias,\n",
        "               name=conv1_reduce_name)(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
        "               name=conv3_name)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
        "\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides, use_bias=bias,\n",
        "                      name=conv1_proj_name)(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=bn_axis, name=conv1_proj_name + \"/bn\")(\n",
        "        shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def RESNET50(include_top=True, weights='vggface',\n",
        "             input_tensor=None, input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=8631):\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=32,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = Conv2D(\n",
        "        64, (7, 7), use_bias=False, strides=(2, 2), padding='same',\n",
        "        name='conv1/7x7_s2')(img_input)\n",
        "    x = BatchNormalization(axis=bn_axis, name='conv1/7x7_s2/bn')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = resnet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
        "    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
        "    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
        "\n",
        "    x = resnet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
        "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
        "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
        "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
        "\n",
        "    x = resnet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
        "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
        "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
        "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
        "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
        "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
        "\n",
        "    x = resnet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
        "    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
        "    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
        "\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(classes, activation='softmax', name='classifier')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='vggface_resnet50')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'vggface':\n",
        "        if include_top:\n",
        "            weights_path = get_file('rcmalli_vggface_tf_resnet50.h5',\n",
        "                                    utils.RESNET50_WEIGHTS_PATH,\n",
        "                                    cache_subdir=utils.VGGFACE_DIR)\n",
        "        else:\n",
        "            weights_path = get_file('rcmalli_vggface_tf_notop_resnet50.h5',\n",
        "                                    utils.RESNET50_WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir=utils.VGGFACE_DIR)\n",
        "        model.load_weights(weights_path)\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "            if include_top:\n",
        "                maxpool = model.get_layer(name='avg_pool')\n",
        "                shape = maxpool.output_shape[1:]\n",
        "                dense = model.get_layer(name='classifier')\n",
        "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
        "                                                              'channels_first')\n",
        "\n",
        "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
        "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                          'are using the Theano '\n",
        "                          'image data format convention '\n",
        "                          '(`image_data_format=\"channels_first\"`). '\n",
        "                          'For best performance, set '\n",
        "                          '`image_data_format=\"channels_last\"` in '\n",
        "                          'your Keras config '\n",
        "                          'at ~/.keras/keras.json.')\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def senet_se_block(input_tensor, stage, block, compress_rate=16, bias=False):\n",
        "    conv1_down_name = 'conv' + str(stage) + \"_\" + str(\n",
        "        block) + \"_1x1_down\"\n",
        "    conv1_up_name = 'conv' + str(stage) + \"_\" + str(\n",
        "        block) + \"_1x1_up\"\n",
        "\n",
        "    num_channels = int(input_tensor.shape[-1])\n",
        "    bottle_neck = int(num_channels // compress_rate)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(input_tensor)\n",
        "    se = Reshape((1, 1, num_channels))(se)\n",
        "    se = Conv2D(bottle_neck, (1, 1), use_bias=bias,\n",
        "                name=conv1_down_name)(se)\n",
        "    se = Activation('relu')(se)\n",
        "    se = Conv2D(num_channels, (1, 1), use_bias=bias,\n",
        "                name=conv1_up_name)(se)\n",
        "    se = Activation('sigmoid')(se)\n",
        "\n",
        "    x = input_tensor\n",
        "    x = multiply([x, se])\n",
        "    return x\n",
        "\n",
        "\n",
        "def senet_conv_block(input_tensor, kernel_size, filters,\n",
        "                     stage, block, bias=False, strides=(2, 2)):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    bn_eps = 0.0001\n",
        "\n",
        "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
        "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
        "        block) + \"_1x1_increase\"\n",
        "    conv1_proj_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\n",
        "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), use_bias=bias, strides=strides,\n",
        "               name=conv1_reduce_name)(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\",epsilon=bn_eps)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
        "               name=conv3_name)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\",epsilon=bn_eps)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\" ,epsilon=bn_eps)(x)\n",
        "\n",
        "    se = senet_se_block(x, stage=stage, block=block, bias=True)\n",
        "\n",
        "    shortcut = Conv2D(filters3, (1, 1), use_bias=bias, strides=strides,\n",
        "                      name=conv1_proj_name)(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=bn_axis,\n",
        "                                  name=conv1_proj_name + \"/bn\",epsilon=bn_eps)(shortcut)\n",
        "\n",
        "    m = layers.add([se, shortcut])\n",
        "    m = Activation('relu')(m)\n",
        "    return m\n",
        "\n",
        "\n",
        "def senet_identity_block(input_tensor, kernel_size,\n",
        "                         filters, stage, block, bias=False):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    bn_eps = 0.0001\n",
        "\n",
        "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
        "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
        "        block) + \"_1x1_increase\"\n",
        "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), use_bias=bias,\n",
        "               name=conv1_reduce_name)(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\",epsilon=bn_eps)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
        "               name=conv3_name)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\",epsilon=bn_eps)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\",epsilon=bn_eps)(x)\n",
        "\n",
        "    se = senet_se_block(x, stage=stage, block=block, bias=True)\n",
        "\n",
        "    m = layers.add([se, input_tensor])\n",
        "    m = Activation('relu')(m)\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def SENET50(include_top=True, weights='vggface',\n",
        "            input_tensor=None, input_shape=None,\n",
        "            pooling=None,\n",
        "            classes=8631):\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=197,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    bn_eps = 0.0001\n",
        "\n",
        "    x = Conv2D(\n",
        "        64, (7, 7), use_bias=False, strides=(2, 2), padding='same',\n",
        "        name='conv1/7x7_s2')(img_input)\n",
        "    x = BatchNormalization(axis=bn_axis, name='conv1/7x7_s2/bn',epsilon=bn_eps)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = senet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
        "    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
        "    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
        "\n",
        "    x = senet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
        "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
        "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
        "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
        "\n",
        "    x = senet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
        "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
        "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
        "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
        "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
        "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
        "\n",
        "    x = senet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
        "    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
        "    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
        "\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(classes, activation='softmax', name='classifier')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='vggface_senet50')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'vggface':\n",
        "        if include_top:\n",
        "            weights_path = get_file('rcmalli_vggface_tf_senet50.h5',\n",
        "                                    utils.SENET50_WEIGHTS_PATH,\n",
        "                                    cache_subdir=utils.VGGFACE_DIR)\n",
        "        else:\n",
        "            weights_path = get_file('rcmalli_vggface_tf_notop_senet50.h5',\n",
        "                                    utils.SENET50_WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir=utils.VGGFACE_DIR)\n",
        "        model.load_weights(weights_path)\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "            if include_top:\n",
        "                maxpool = model.get_layer(name='avg_pool')\n",
        "                shape = maxpool.output_shape[1:]\n",
        "                dense = model.get_layer(name='classifier')\n",
        "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
        "                                                              'channels_first')\n",
        "\n",
        "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
        "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                          'are using the Theano '\n",
        "                          'image data format convention '\n",
        "                          '(`image_data_format=\"channels_first\"`). '\n",
        "                          'For best performance, set '\n",
        "                          '`image_data_format=\"channels_last\"` in '\n",
        "                          'your Keras config '\n",
        "                          'at ~/.keras/keras.json.')\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'VGGFace models for Keras.\\n\\n# Notes:\\n- Resnet50 and VGG16  are modified architectures from Keras Application folder. [Keras](https://keras.io)\\n\\n- Squeeze and excitation block is taken from  [Squeeze and Excitation Networks in\\n Keras](https://github.com/titu1994/keras-squeeze-excite-network) and modified.\\n\\n\\n\\nfrom tensorflow.keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D,     GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization,     AveragePooling2D, Reshape, Permute, multiply\\nfrom keras_applications.imagenet_utils import _obtain_input_shape\\nfrom keras.utils import layer_utils\\nfrom keras.utils.data_utils import get_file\\nfrom tensorflow.keras import backend as K\\nfrom keras_vggface import utils\\nfrom keras.engine.topology import get_source_inputs\\nimport warnings\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras import layers\\n\\n\\ndef VGG16(include_top=True, weights=\\'vggface\\',\\n          input_tensor=None, input_shape=None,\\n          pooling=None,\\n          classes=2622):\\n    input_shape = _obtain_input_shape(input_shape,\\n                                      default_size=224,\\n                                      min_size=48,\\n                                      data_format=K.image_data_format(),\\n                                      require_flatten=include_top)\\n    \\n    if input_tensor is None:\\n        img_input = Input(shape=input_shape)\\n    else:\\n        if not K.is_keras_tensor(input_tensor):\\n            img_input = Input(tensor=input_tensor, shape=input_shape)\\n        else:\\n            img_input = input_tensor\\n    \\n    # Block 1\\n    x = Conv2D(64, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv1_1\\')(img_input)\\n    x = Conv2D(64, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv1_2\\')(x)\\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\\'pool1\\')(x)\\n\\n    # Block 2\\n    x = Conv2D(128, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv2_1\\')(\\n        x)\\n    x = Conv2D(128, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv2_2\\')(\\n        x)\\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\\'pool2\\')(x)\\n\\n    # Block 3\\n    x = Conv2D(256, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv3_1\\')(\\n        x)\\n    x = Conv2D(256, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv3_2\\')(\\n        x)\\n    x = Conv2D(256, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv3_3\\')(\\n        x)\\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\\'pool3\\')(x)\\n\\n    # Block 4\\n    x = Conv2D(512, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv4_1\\')(\\n        x)\\n    x = Conv2D(512, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv4_2\\')(\\n        x)\\n    x = Conv2D(512, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv4_3\\')(\\n        x)\\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\\'pool4\\')(x)\\n\\n    # Block 5\\n    x = Conv2D(512, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv5_1\\')(\\n        x)\\n    x = Conv2D(512, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv5_2\\')(\\n        x)\\n    x = Conv2D(512, (3, 3), activation=\\'relu\\', padding=\\'same\\', name=\\'conv5_3\\')(\\n        x)\\n    x = MaxPooling2D((2, 2), strides=(2, 2), name=\\'pool5\\')(x)\\n\\n    if include_top:\\n        # Classification block\\n        x = Flatten(name=\\'flatten\\')(x)\\n        x = Dense(4096, name=\\'fc6\\')(x)\\n        x = Activation(\\'relu\\', name=\\'fc6/relu\\')(x)\\n        x = Dense(4096, name=\\'fc7\\')(x)\\n        x = Activation(\\'relu\\', name=\\'fc7/relu\\')(x)\\n        x = Dense(classes, name=\\'fc8\\')(x)\\n        x = Activation(\\'softmax\\', name=\\'fc8/softmax\\')(x)\\n    else:\\n        if pooling == \\'avg\\':\\n            x = GlobalAveragePooling2D()(x)\\n        elif pooling == \\'max\\':\\n            x = GlobalMaxPooling2D()(x)\\n\\n            # Ensure that the model takes into account\\n            # any potential predecessors of `input_tensor`.\\n    if input_tensor is not None:\\n        inputs = get_source_inputs(input_tensor)\\n    else:\\n        inputs = img_input\\n        # Create model.\\n    model = Model(inputs, x, name=\\'vggface_vgg16\\')  # load weights\\n    if weights == \\'vggface\\':\\n        if include_top:\\n            weights_path = get_file(\\'rcmalli_vggface_tf_vgg16.h5\\',\\n                                    utils.\\n                                    VGG16_WEIGHTS_PATH,\\n                                    cache_subdir=utils.VGGFACE_DIR)\\n        else:\\n            weights_path = get_file(\\'rcmalli_vggface_tf_notop_vgg16.h5\\',\\n                                    utils.VGG16_WEIGHTS_PATH_NO_TOP,\\n                                    cache_subdir=utils.VGGFACE_DIR)\\n        model.load_weights(weights_path, by_name=True)\\n        if K.backend() == \\'theano\\':\\n            layer_utils.convert_all_kernels_in_model(model)\\n\\n        if K.image_data_format() == \\'channels_first\\':\\n            if include_top:\\n                maxpool = model.get_layer(name=\\'pool5\\')\\n                shape = maxpool.output_shape[1:]\\n                dense = model.get_layer(name=\\'fc6\\')\\n                layer_utils.convert_dense_weights_data_format(dense, shape,\\n                                                              \\'channels_first\\')\\n\\n            if K.backend() == \\'tensorflow\\':\\n                warnings.warn(\\'You are using the TensorFlow backend, yet you \\'\\n                              \\'are using the Theano \\'\\n                              \\'image data format convention \\'\\n                              \\'(`image_data_format=\"channels_first\"`). \\'\\n                              \\'For best performance, set \\'\\n                              \\'`image_data_format=\"channels_last\"` in \\'\\n                              \\'your Keras config \\'\\n                              \\'at ~/.keras/keras.json.\\')\\n    return model\\n\\n\\ndef resnet_identity_block(input_tensor, kernel_size, filters, stage, block,\\n                          bias=False):\\n    filters1, filters2, filters3 = filters\\n    if K.image_data_format() == \\'channels_last\\':\\n        bn_axis = 3\\n    else:\\n        bn_axis = 1\\n    conv1_reduce_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\\n    conv1_increase_name = \\'conv\\' + str(stage) + \"_\" + str(\\n        block) + \"_1x1_increase\"\\n    conv3_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_3x3\"\\n\\n    x = Conv2D(filters1, (1, 1), use_bias=bias, name=conv1_reduce_name)(\\n        input_tensor)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters2, kernel_size, use_bias=bias,\\n               padding=\\'same\\', name=conv3_name)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters3, (1, 1), use_bias=bias, name=conv1_increase_name)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\\n\\n    x = layers.add([x, input_tensor])\\n    x = Activation(\\'relu\\')(x)\\n    return x\\n\\n\\ndef resnet_conv_block(input_tensor, kernel_size, filters, stage, block,\\n                      strides=(2, 2), bias=False):\\n    filters1, filters2, filters3 = filters\\n    if K.image_data_format() == \\'channels_last\\':\\n        bn_axis = 3\\n    else:\\n        bn_axis = 1\\n    conv1_reduce_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\\n    conv1_increase_name = \\'conv\\' + str(stage) + \"_\" + str(\\n        block) + \"_1x1_increase\"\\n    conv1_proj_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\\n    conv3_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_3x3\"\\n\\n    x = Conv2D(filters1, (1, 1), strides=strides, use_bias=bias,\\n               name=conv1_reduce_name)(input_tensor)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters2, kernel_size, padding=\\'same\\', use_bias=bias,\\n               name=conv3_name)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\\n\\n    shortcut = Conv2D(filters3, (1, 1), strides=strides, use_bias=bias,\\n                      name=conv1_proj_name)(input_tensor)\\n    shortcut = BatchNormalization(axis=bn_axis, name=conv1_proj_name + \"/bn\")(\\n        shortcut)\\n\\n    x = layers.add([x, shortcut])\\n    x = Activation(\\'relu\\')(x)\\n    return x\\n\\n\\ndef RESNET50(include_top=True, weights=\\'vggface\\',\\n             input_tensor=None, input_shape=None,\\n             pooling=None,\\n             classes=8631):\\n    input_shape = _obtain_input_shape(input_shape,\\n                                      default_size=224,\\n                                      min_size=32,\\n                                      data_format=K.image_data_format(),\\n                                      require_flatten=include_top,\\n                                      weights=weights)\\n\\n    if input_tensor is None:\\n        img_input = Input(shape=input_shape)\\n    else:\\n        if not K.is_keras_tensor(input_tensor):\\n            img_input = Input(tensor=input_tensor, shape=input_shape)\\n        else:\\n            img_input = input_tensor\\n    if K.image_data_format() == \\'channels_last\\':\\n        bn_axis = 3\\n    else:\\n        bn_axis = 1\\n\\n    x = Conv2D(\\n        64, (7, 7), use_bias=False, strides=(2, 2), padding=\\'same\\',\\n        name=\\'conv1/7x7_s2\\')(img_input)\\n    x = BatchNormalization(axis=bn_axis, name=\\'conv1/7x7_s2/bn\\')(x)\\n    x = Activation(\\'relu\\')(x)\\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\\n\\n    x = resnet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\\n    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\\n    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\\n\\n    x = resnet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\\n    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\\n    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\\n    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\\n\\n    x = resnet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\\n    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\\n\\n    x = resnet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\\n    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\\n    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\\n\\n    x = AveragePooling2D((7, 7), name=\\'avg_pool\\')(x)\\n\\n    if include_top:\\n        x = Flatten()(x)\\n        x = Dense(classes, activation=\\'softmax\\', name=\\'classifier\\')(x)\\n    else:\\n        if pooling == \\'avg\\':\\n            x = GlobalAveragePooling2D()(x)\\n        elif pooling == \\'max\\':\\n            x = GlobalMaxPooling2D()(x)\\n\\n    # Ensure that the model takes into account\\n    # any potential predecessors of `input_tensor`.\\n    if input_tensor is not None:\\n        inputs = get_source_inputs(input_tensor)\\n    else:\\n        inputs = img_input\\n    # Create model.\\n    model = Model(inputs, x, name=\\'vggface_resnet50\\')\\n\\n    # load weights\\n    if weights == \\'vggface\\':\\n        if include_top:\\n            weights_path = get_file(\\'rcmalli_vggface_tf_resnet50.h5\\',\\n                                    utils.RESNET50_WEIGHTS_PATH,\\n                                    cache_subdir=utils.VGGFACE_DIR)\\n        else:\\n            weights_path = get_file(\\'rcmalli_vggface_tf_notop_resnet50.h5\\',\\n                                    utils.RESNET50_WEIGHTS_PATH_NO_TOP,\\n                                    cache_subdir=utils.VGGFACE_DIR)\\n        model.load_weights(weights_path)\\n        if K.backend() == \\'theano\\':\\n            layer_utils.convert_all_kernels_in_model(model)\\n            if include_top:\\n                maxpool = model.get_layer(name=\\'avg_pool\\')\\n                shape = maxpool.output_shape[1:]\\n                dense = model.get_layer(name=\\'classifier\\')\\n                layer_utils.convert_dense_weights_data_format(dense, shape,\\n                                                              \\'channels_first\\')\\n\\n        if K.image_data_format() == \\'channels_first\\' and K.backend() == \\'tensorflow\\':\\n            warnings.warn(\\'You are using the TensorFlow backend, yet you \\'\\n                          \\'are using the Theano \\'\\n                          \\'image data format convention \\'\\n                          \\'(`image_data_format=\"channels_first\"`). \\'\\n                          \\'For best performance, set \\'\\n                          \\'`image_data_format=\"channels_last\"` in \\'\\n                          \\'your Keras config \\'\\n                          \\'at ~/.keras/keras.json.\\')\\n    elif weights is not None:\\n        model.load_weights(weights)\\n\\n    return model\\n\\n\\ndef senet_se_block(input_tensor, stage, block, compress_rate=16, bias=False):\\n    conv1_down_name = \\'conv\\' + str(stage) + \"_\" + str(\\n        block) + \"_1x1_down\"\\n    conv1_up_name = \\'conv\\' + str(stage) + \"_\" + str(\\n        block) + \"_1x1_up\"\\n\\n    num_channels = int(input_tensor.shape[-1])\\n    bottle_neck = int(num_channels // compress_rate)\\n\\n    se = GlobalAveragePooling2D()(input_tensor)\\n    se = Reshape((1, 1, num_channels))(se)\\n    se = Conv2D(bottle_neck, (1, 1), use_bias=bias,\\n                name=conv1_down_name)(se)\\n    se = Activation(\\'relu\\')(se)\\n    se = Conv2D(num_channels, (1, 1), use_bias=bias,\\n                name=conv1_up_name)(se)\\n    se = Activation(\\'sigmoid\\')(se)\\n\\n    x = input_tensor\\n    x = multiply([x, se])\\n    return x\\n\\n\\ndef senet_conv_block(input_tensor, kernel_size, filters,\\n                     stage, block, bias=False, strides=(2, 2)):\\n    filters1, filters2, filters3 = filters\\n    if K.image_data_format() == \\'channels_last\\':\\n        bn_axis = 3\\n    else:\\n        bn_axis = 1\\n\\n    bn_eps = 0.0001\\n\\n    conv1_reduce_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\\n    conv1_increase_name = \\'conv\\' + str(stage) + \"_\" + str(\\n        block) + \"_1x1_increase\"\\n    conv1_proj_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\\n    conv3_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_3x3\"\\n\\n    x = Conv2D(filters1, (1, 1), use_bias=bias, strides=strides,\\n               name=conv1_reduce_name)(input_tensor)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\",epsilon=bn_eps)(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters2, kernel_size, padding=\\'same\\', use_bias=bias,\\n               name=conv3_name)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\",epsilon=bn_eps)(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\" ,epsilon=bn_eps)(x)\\n\\n    se = senet_se_block(x, stage=stage, block=block, bias=True)\\n\\n    shortcut = Conv2D(filters3, (1, 1), use_bias=bias, strides=strides,\\n                      name=conv1_proj_name)(input_tensor)\\n    shortcut = BatchNormalization(axis=bn_axis,\\n                                  name=conv1_proj_name + \"/bn\",epsilon=bn_eps)(shortcut)\\n\\n    m = layers.add([se, shortcut])\\n    m = Activation(\\'relu\\')(m)\\n    return m\\n\\n\\ndef senet_identity_block(input_tensor, kernel_size,\\n                         filters, stage, block, bias=False):\\n    filters1, filters2, filters3 = filters\\n    if K.image_data_format() == \\'channels_last\\':\\n        bn_axis = 3\\n    else:\\n        bn_axis = 1\\n\\n    bn_eps = 0.0001\\n\\n    conv1_reduce_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\\n    conv1_increase_name = \\'conv\\' + str(stage) + \"_\" + str(\\n        block) + \"_1x1_increase\"\\n    conv3_name = \\'conv\\' + str(stage) + \"_\" + str(block) + \"_3x3\"\\n\\n    x = Conv2D(filters1, (1, 1), use_bias=bias,\\n               name=conv1_reduce_name)(input_tensor)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\",epsilon=bn_eps)(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters2, kernel_size, padding=\\'same\\', use_bias=bias,\\n               name=conv3_name)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\",epsilon=bn_eps)(x)\\n    x = Activation(\\'relu\\')(x)\\n\\n    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\\n    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\",epsilon=bn_eps)(x)\\n\\n    se = senet_se_block(x, stage=stage, block=block, bias=True)\\n\\n    m = layers.add([se, input_tensor])\\n    m = Activation(\\'relu\\')(m)\\n\\n    return m\\n\\n\\ndef SENET50(include_top=True, weights=\\'vggface\\',\\n            input_tensor=None, input_shape=None,\\n            pooling=None,\\n            classes=8631):\\n    input_shape = _obtain_input_shape(input_shape,\\n                                      default_size=224,\\n                                      min_size=197,\\n                                      data_format=K.image_data_format(),\\n                                      require_flatten=include_top,\\n                                      weights=weights)\\n\\n    if input_tensor is None:\\n        img_input = Input(shape=input_shape)\\n    else:\\n        if not K.is_keras_tensor(input_tensor):\\n            img_input = Input(tensor=input_tensor, shape=input_shape)\\n        else:\\n            img_input = input_tensor\\n    if K.image_data_format() == \\'channels_last\\':\\n        bn_axis = 3\\n    else:\\n        bn_axis = 1\\n\\n    bn_eps = 0.0001\\n\\n    x = Conv2D(\\n        64, (7, 7), use_bias=False, strides=(2, 2), padding=\\'same\\',\\n        name=\\'conv1/7x7_s2\\')(img_input)\\n    x = BatchNormalization(axis=bn_axis, name=\\'conv1/7x7_s2/bn\\',epsilon=bn_eps)(x)\\n    x = Activation(\\'relu\\')(x)\\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\\n\\n    x = senet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\\n    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\\n    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\\n\\n    x = senet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\\n    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\\n    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\\n    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\\n\\n    x = senet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\\n    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\\n\\n    x = senet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\\n    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\\n    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\\n\\n    x = AveragePooling2D((7, 7), name=\\'avg_pool\\')(x)\\n\\n    if include_top:\\n        x = Flatten()(x)\\n        x = Dense(classes, activation=\\'softmax\\', name=\\'classifier\\')(x)\\n    else:\\n        if pooling == \\'avg\\':\\n            x = GlobalAveragePooling2D()(x)\\n        elif pooling == \\'max\\':\\n            x = GlobalMaxPooling2D()(x)\\n\\n    # Ensure that the model takes into account\\n    # any potential predecessors of `input_tensor`.\\n    if input_tensor is not None:\\n        inputs = get_source_inputs(input_tensor)\\n    else:\\n        inputs = img_input\\n    # Create model.\\n    model = Model(inputs, x, name=\\'vggface_senet50\\')\\n\\n    # load weights\\n    if weights == \\'vggface\\':\\n        if include_top:\\n            weights_path = get_file(\\'rcmalli_vggface_tf_senet50.h5\\',\\n                                    utils.SENET50_WEIGHTS_PATH,\\n                                    cache_subdir=utils.VGGFACE_DIR)\\n        else:\\n            weights_path = get_file(\\'rcmalli_vggface_tf_notop_senet50.h5\\',\\n                                    utils.SENET50_WEIGHTS_PATH_NO_TOP,\\n                                    cache_subdir=utils.VGGFACE_DIR)\\n        model.load_weights(weights_path)\\n        if K.backend() == \\'theano\\':\\n            layer_utils.convert_all_kernels_in_model(model)\\n            if include_top:\\n                maxpool = model.get_layer(name=\\'avg_pool\\')\\n                shape = maxpool.output_shape[1:]\\n                dense = model.get_layer(name=\\'classifier\\')\\n                layer_utils.convert_dense_weights_data_format(dense, shape,\\n                                                              \\'channels_first\\')\\n\\n        if K.image_data_format() == \\'channels_first\\' and K.backend() == \\'tensorflow\\':\\n            warnings.warn(\\'You are using the TensorFlow backend, yet you \\'\\n                          \\'are using the Theano \\'\\n                          \\'image data format convention \\'\\n                          \\'(`image_data_format=\"channels_first\"`). \\'\\n                          \\'For best performance, set \\'\\n                          \\'`image_data_format=\"channels_last\"` in \\'\\n                          \\'your Keras config \\'\\n                          \\'at ~/.keras/keras.json.\\')\\n    elif weights is not None:\\n        model.load_weights(weights)\\n\\n    return model\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHxaxdUgPVAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8c032780-8996-4961-8d11-bac92eabf2d9"
      },
      "source": [
        "'''VGGFace models for Keras.\n",
        "\n",
        "# Reference:\n",
        "- [Deep Face Recognition](http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf)\n",
        "- [VGGFace2: A dataset for recognising faces across pose and age](http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/vggface2.pdf)\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "def VGGFace(include_top=True, model='vgg16', weights='vggface',\n",
        "            input_tensor=None, input_shape=None,\n",
        "            pooling=None,\n",
        "            classes=None):\n",
        "    \"\"\"Instantiates the VGGFace architectures.\n",
        "    Optionally loads weights pre-trained\n",
        "    on VGGFace datasets. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_data_format=\"channels_last\"` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The data format\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "    # Arguments\n",
        "        include_top: whether to include the 3 fully-connected\n",
        "            layers at the top of the network.\n",
        "        weights: one of `None` (random initialization)\n",
        "            or \"vggface\" (pre-training on VGGFACE datasets).\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        model: selects the one of the available architectures \n",
        "            vgg16, resnet50 or senet50 default is vgg16.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 244)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 48.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "\n",
        "    if weights not in {'vggface', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `vggface`'\n",
        "                         '(pre-training on VGGFace Datasets).')\n",
        "\n",
        "    if model == 'vgg16':\n",
        "\n",
        "        if classes is None:\n",
        "            classes = 2622\n",
        "\n",
        "        if weights == 'vggface' and include_top and classes != 2622:\n",
        "            raise ValueError(\n",
        "                'If using `weights` as vggface original with `include_top`'\n",
        "                ' as true, `classes` should be 2622')\n",
        "\n",
        "        return VGG16(include_top=include_top, input_tensor=input_tensor,\n",
        "                     input_shape=input_shape, pooling=pooling,\n",
        "                     weights=weights,\n",
        "                     classes=classes)\n",
        "\n",
        "\n",
        "    if model == 'resnet50':\n",
        "\n",
        "        if classes is None:\n",
        "            classes = 8631\n",
        "\n",
        "        if weights == 'vggface' and include_top and classes != 8631:\n",
        "            raise ValueError(\n",
        "                'If using `weights` as vggface original with `include_top`'\n",
        "                ' as true, `classes` should be 8631')\n",
        "            \n",
        "\n",
        "        return RESNET50(include_top=include_top, input_tensor=input_tensor,\n",
        "                        input_shape=input_shape, pooling=pooling,\n",
        "                        weights=weights,\n",
        "                        classes=classes)\n",
        "\n",
        "    if model == 'senet50':\n",
        "\n",
        "        if classes is None:\n",
        "            classes = 8631\n",
        "\n",
        "        if weights == 'vggface' and include_top and classes != 8631:\n",
        "            raise ValueError(\n",
        "                'If using `weights` as vggface original with `include_top`'\n",
        "                ' as true, `classes` should be 8631')\n",
        "\n",
        "        return SENET50(include_top=include_top, input_tensor=input_tensor,\n",
        "                        input_shape=input_shape, pooling=pooling,\n",
        "                        weights=weights,\n",
        "                        classes=classes)\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d91ced675451>\"\u001b[0;36m, line \u001b[0;32m112\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFAVQ7N7XYwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ee22d51c-feeb-4a0a-b7f9-46633733caaf"
      },
      "source": [
        "_# face verification with the VGGFace2 model\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from scipy.spatial.distance import cosine\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(224, 224)):\n",
        "\t# load image from file\n",
        "\tpixels = pyplot.imread(filename)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "\n",
        "# extract faces and calculate face embeddings for a list of photo files\n",
        "def get_embeddings(filenames):\n",
        "\t# extract faces\n",
        "\tfaces = [extract_face(f) for f in filenames]\n",
        "\t# convert into an array of samples\n",
        "\tsamples = asarray(faces, 'float32')\n",
        "\t# prepare the face for the model, e.g. center pixels\n",
        "\tsamples = preprocess_input(samples, version=2)\n",
        "\t# create a vggface model\n",
        "  print(samples)\n",
        "  print(samples.shape)\n",
        "\tmodel = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\t# perform prediction\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat\n",
        "\n",
        "embeddings = get_embeddings(f)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXbMRIB8XYuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b184cc64-a28e-434e-c478-7e8ba1d72e45"
      },
      "source": [
        "embeddings"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.6663566e-02, 9.6299648e-01, 1.7681995e-01, ..., 1.1269286e+00,\n",
              "        1.8694632e-01, 0.0000000e+00],\n",
              "       [3.4382320e-03, 3.2605079e-01, 8.8442338e-01, ..., 1.0139080e-01,\n",
              "        8.1121981e-01, 4.4080889e-01],\n",
              "       [7.2877874e+00, 3.1905100e-01, 1.2724630e+00, ..., 3.5127757e+00,\n",
              "        8.7759703e-01, 1.5965286e-04],\n",
              "       ...,\n",
              "       [1.3959834e+01, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
              "        2.3562360e+00, 1.0428590e+00],\n",
              "       [1.2057389e+00, 1.1040424e+00, 3.2777426e+00, ..., 0.0000000e+00,\n",
              "        0.0000000e+00, 2.2961733e+00],\n",
              "       [1.9995850e-02, 0.0000000e+00, 1.3471788e+00, ..., 3.7983835e+00,\n",
              "        1.9359640e+00, 2.6511335e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvw-2OQHXYr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da03773f-7aa9-4c9b-e22b-023f35afbb4d"
      },
      "source": [
        "len(embeddings)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3cJDvfOXYoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "860d387f-2662-4958-cda9-919980b218d0"
      },
      "source": [
        "for i in range(len(f)):\n",
        "  f[i] = f[i].split('/')[5]\n",
        "\n",
        "f"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arsene_Wenger.jpg',\n",
              " 'Channing_Tatum.jpg',\n",
              " 'Suzanne_Shaw.jpg',\n",
              " 'Joaquin_Phoenix.jpg',\n",
              " 'Alyson_Hannigan.jpg',\n",
              " 'David_Alaba.jpg',\n",
              " 'Brie_Larson.jpg',\n",
              " 'Sebastian_Vettel.jpg',\n",
              " 'Elizabeth_Olsen.jpg',\n",
              " 'Kajal_Aggarwal.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFj41ytCXYlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(f)-1):\n",
        "  df[f[i]] = list(embeddings[i])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJbJiPkwXYjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "70c4ee83-8e23-41ac-bdf9-4ccfbd9ae7b0"
      },
      "source": [
        "df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Arsene_Wenger.jpg</th>\n",
              "      <th>Channing_Tatum.jpg</th>\n",
              "      <th>Suzanne_Shaw.jpg</th>\n",
              "      <th>Joaquin_Phoenix.jpg</th>\n",
              "      <th>Alyson_Hannigan.jpg</th>\n",
              "      <th>David_Alaba.jpg</th>\n",
              "      <th>Brie_Larson.jpg</th>\n",
              "      <th>Sebastian_Vettel.jpg</th>\n",
              "      <th>Elizabeth_Olsen.jpg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.026664</td>\n",
              "      <td>0.003438</td>\n",
              "      <td>7.287787</td>\n",
              "      <td>2.615009</td>\n",
              "      <td>10.211094</td>\n",
              "      <td>5.204028</td>\n",
              "      <td>0.792291</td>\n",
              "      <td>13.959834</td>\n",
              "      <td>1.205739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.962996</td>\n",
              "      <td>0.326051</td>\n",
              "      <td>0.319051</td>\n",
              "      <td>0.073866</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.795300</td>\n",
              "      <td>0.660623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.104042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.176820</td>\n",
              "      <td>0.884423</td>\n",
              "      <td>1.272463</td>\n",
              "      <td>0.022776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422715</td>\n",
              "      <td>0.652062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.277743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.025856</td>\n",
              "      <td>0.799032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011135</td>\n",
              "      <td>3.377105</td>\n",
              "      <td>1.023647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.735233</td>\n",
              "      <td>0.448290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.094138</td>\n",
              "      <td>3.480408</td>\n",
              "      <td>1.709928</td>\n",
              "      <td>0.099040</td>\n",
              "      <td>0.322407</td>\n",
              "      <td>4.749907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.643640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2043</th>\n",
              "      <td>0.017205</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006769</td>\n",
              "      <td>3.279908</td>\n",
              "      <td>1.200256</td>\n",
              "      <td>0.542951</td>\n",
              "      <td>0.010526</td>\n",
              "      <td>0.072805</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2044</th>\n",
              "      <td>0.557395</td>\n",
              "      <td>0.486283</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.174508</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.245049</td>\n",
              "      <td>1.620390</td>\n",
              "      <td>0.044568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2045</th>\n",
              "      <td>1.126929</td>\n",
              "      <td>0.101391</td>\n",
              "      <td>3.512776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016456</td>\n",
              "      <td>5.398932</td>\n",
              "      <td>9.186919</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2046</th>\n",
              "      <td>0.186946</td>\n",
              "      <td>0.811220</td>\n",
              "      <td>0.877597</td>\n",
              "      <td>4.503322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.783289</td>\n",
              "      <td>2.525741</td>\n",
              "      <td>2.356236</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2047</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.440809</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.219530</td>\n",
              "      <td>1.417575</td>\n",
              "      <td>0.008907</td>\n",
              "      <td>1.042859</td>\n",
              "      <td>2.296173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2048 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Arsene_Wenger.jpg  ...  Elizabeth_Olsen.jpg\n",
              "0              0.026664  ...             1.205739\n",
              "1              0.962996  ...             1.104042\n",
              "2              0.176820  ...             3.277743\n",
              "3              0.025856  ...             0.448290\n",
              "4              0.000000  ...             0.643640\n",
              "...                 ...  ...                  ...\n",
              "2043           0.017205  ...             0.000000\n",
              "2044           0.557395  ...             0.044568\n",
              "2045           1.126929  ...             0.000000\n",
              "2046           0.186946  ...             0.000000\n",
              "2047           0.000000  ...             2.296173\n",
              "\n",
              "[2048 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "746Yll0OdJYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5fbc63dc-a706-4db9-bdfc-1163dfcf1f6f"
      },
      "source": [
        "df[f[8]]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1.205739\n",
              "1       1.104042\n",
              "2       3.277743\n",
              "3       0.448290\n",
              "4       0.643640\n",
              "          ...   \n",
              "2043    0.000000\n",
              "2044    0.044568\n",
              "2045    0.000000\n",
              "2046    0.000000\n",
              "2047    2.296173\n",
              "Name: Elizabeth_Olsen.jpg, Length: 2048, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSmh0GpxdRNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8de1aa65-3bfd-463e-c86d-3078cc326f18"
      },
      "source": [
        "embeddings[8]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.2057389, 1.1040424, 3.2777426, ..., 0.       , 0.       ,\n",
              "       2.2961733], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8079Y3h6a94v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_embed = get_embeddings([fpath+'/testimages/eo1.jpg'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHInSiGGbgdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61ae0c7f-b53f-48f6-ba84-bfe1678a51f5"
      },
      "source": [
        "new_embed"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.322706  , 4.7730403 , 2.5647454 , ..., 0.17429346, 1.0706133 ,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrf544GLfI70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ne = new_embed"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E4WT5M_fPgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb = embeddings"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2jeiEZ4iOre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rlaoBEWABbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzLqLd1ildvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb1 = []\n",
        "for i in range(len(emb)):\n",
        "  data_np = np.asarray(emb[i], np.float32)\n",
        "  data_em = tf.convert_to_tensor(data_np, np.float32)\n",
        "  emb1.append(data_em)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFEBkvDuoORo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lamb1 = np.array(0.5)\n",
        "data_np = np.asarray(lamb1, np.float32)\n",
        "data_lamb1 = tf.convert_to_tensor(data_np, np.float32)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0d4STrJe1iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_np = np.asarray(ne, np.float32)\n",
        "data_em = tf.convert_to_tensor(data_np, np.float32)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fGMqCNqXYhP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3f510c39-fb9d-445b-e65c-d08a42557b3f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tf_encrypted as tfe\n",
        "\n",
        "'''\n",
        "@tfe.local_computation('players')\n",
        "def provide_input():\n",
        "    # normal TensorFlow operations can be run locally\n",
        "    # as part of defining a private input, in this\n",
        "    # case on the machine of the input provider\n",
        "    \n",
        "    newl = emb\n",
        "\n",
        "    \n",
        "    return newl\n",
        "'''\n",
        "\n",
        "\n",
        "prot = tfe.protocol.SecureNN()\n",
        "tfe.set_protocol(prot)\n",
        "\n",
        "  # define inputs\n",
        "w = tfe.define_private_variable(data_em)\n",
        "\n",
        "x = []\n",
        "for i in range(len(emb1)):\n",
        "  x.append(tfe.define_private_variable(emb1[i]))\n",
        "\n",
        "\n",
        "print(w)\n",
        "print(x)\n",
        "\n",
        "y = []\n",
        "for i in range(len(x)):\n",
        "  y.append(tfe.sub(x[i], w))\n",
        "\n",
        "\n",
        "lessthan = []\n",
        "lambdaa = tfe.define_private_variable(data_lamb1)\n",
        "for i in range(len(x)):\n",
        "  ynew = tfe.less(y[i], lambdaa)\n",
        "  lessthan.append(ynew)\n",
        "\n",
        "print(lessthan)\n",
        "'''\n",
        "def lessthan(d, lam=0.5):\n",
        "    if d < lam:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  newl = []\n",
        "  for i in range(len(y)):\n",
        "    newl.append(lessthan(y[i]))\n",
        "\n",
        "'''\n",
        "\n",
        "with tfe.Session() as sess:\n",
        "  # initialize variables\n",
        "  sess.run(tfe.global_variables_initializer())\n",
        "  # reveal result\n",
        "  res = []\n",
        "  for i in range(len(lessthan)):\n",
        "    result = sess.run(lessthan[i].reveal())\n",
        "    res.append(result)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PondPrivateVariable(shape=(1, 2048))\n",
            "[PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,)), PondPrivateVariable(shape=(2048,))]\n",
            "[PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048)), PondPrivateTensor(shape=(1, 2048))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZZyhrxxXYeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c75a689d-1bc5-40d6-b53a-bcfd34013df2"
      },
      "source": [
        "print(res)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[1, 1, 1, ..., 0, 1, 1]]), array([[1, 1, 1, ..., 1, 1, 1]]), array([[1, 1, 1, ..., 0, 1, 1]]), array([[1, 1, 1, ..., 1, 0, 1]]), array([[0, 1, 1, ..., 1, 1, 0]]), array([[1, 1, 1, ..., 0, 1, 0]]), array([[1, 1, 1, ..., 0, 0, 1]]), array([[0, 1, 1, ..., 1, 0, 0]]), array([[1, 1, 0, ..., 1, 1, 0]]), array([[1, 1, 1, ..., 0, 0, 0]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI4xc2lyJpfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1fdf18e9-bb00-4660-d4ed-528791ee231c"
      },
      "source": [
        "for i in range(len(res)):\n",
        "  num_ones = (res[i] == 1).sum()\n",
        "  print(num_ones)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1371\n",
            "1441\n",
            "1460\n",
            "1444\n",
            "1472\n",
            "1457\n",
            "1412\n",
            "1377\n",
            "1480\n",
            "1425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15V3N_tTJpdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzcCRJTBY53f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfvDJV8DY51E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaeFswryY5xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LeFX3DQY5vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnd-r-6D_VrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "42321d50-bdf1-46ad-9b24-6f1024dcb8f2"
      },
      "source": [
        "# Example of face detection with a vggface2 model\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(224, 224)):\n",
        "\t# load image from file\n",
        "\tpixels = pyplot.imread(filename)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "\n",
        "# load the photo and extract the face\n",
        "pixels = extract_face('/content/gdrive/My Drive/Face_images/Channing_Tatum.jpg')\n",
        "# convert one face into samples\n",
        "pixels = pixels.astype('float32')\n",
        "samples = expand_dims(pixels, axis=0)\n",
        "# prepare the face for the model, e.g. center pixels\n",
        "samples = preprocess_input(samples, version=2)\n",
        "# create a vggface model\n",
        "model = VGGFace(model='resnet50')\n",
        "# perform prediction\n",
        "yhat = model.predict(samples)\n",
        "print(yhat)\n",
        "print(len(yhat[0]))\n",
        "# convert prediction into names\n",
        "results = decode_predictions(yhat)\n",
        "# display most likely results\n",
        "for result in results[0]:\n",
        "\tprint('%s: %.3f%%' % (result[0], result[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "[[1.0087899e-07 5.1767080e-07 2.1022200e-07 ... 3.6320075e-06\n",
            "  1.4810366e-06 7.8079688e-07]]\n",
            "8631\n",
            "b' Channing_Tatum': 91.401%\n",
            "b' Jeff_Corwin': 0.408%\n",
            "b' Jill_Goodacre': 0.251%\n",
            "b' Vince_Gill': 0.227%\n",
            "b' Ryan_Peake': 0.204%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeWW1vPjA9_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "05125862-e49d-4842-da36-3a4a76154073"
      },
      "source": [
        "# face verification with the VGGFace2 model\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from scipy.spatial.distance import cosine\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(224, 224)):\n",
        "\t# load image from file\n",
        "\tpixels = pyplot.imread(filename)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "\n",
        "# extract faces and calculate face embeddings for a list of photo files\n",
        "def get_embeddings(filenames):\n",
        "\t# extract faces\n",
        "\tfaces = [extract_face(f) for f in filenames]\n",
        "\t# convert into an array of samples\n",
        "\tsamples = asarray(faces, 'float32')\n",
        "\t# prepare the face for the model, e.g. center pixels\n",
        "\tsamples = preprocess_input(samples, version=2)\n",
        "\t# create a vggface model\n",
        "\tmodel = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\t# perform prediction\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat\n",
        "\n",
        "# determine if a candidate face is a match for a known face\n",
        "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
        "\t# calculate distance between embeddings\n",
        "\tscore = cosine(known_embedding, candidate_embedding)\n",
        "\tif score <= thresh:\n",
        "\t\tprint('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n",
        "\telse:\n",
        "\t\tprint('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))\n",
        "\n",
        "# define filenames\n",
        "filenames = ['/content/gdrive/My Drive/Face_images/Channing_Tatum.jpg', \\\n",
        "             '/content/gdrive/My Drive/Face_images/Barack_Obama.jpg', \\\n",
        "             '/content/gdrive/My Drive/Face_images/Arsene_Wenger.jpg', \\\n",
        "             '/content/gdrive/My Drive/channing_tatum.jpg']\n",
        "# get embeddings file filenames\n",
        "embeddings = get_embeddings(filenames)\n",
        "# define sharon stone\n",
        "sharon_id = embeddings[0]\n",
        "# verify known photos of sharon\n",
        "print('Positive Tests')\n",
        "is_match(embeddings[0], embeddings[1])\n",
        "is_match(embeddings[0], embeddings[2])\n",
        "# verify known photos of other people\n",
        "print('Negative Tests')\n",
        "is_match(embeddings[0], embeddings[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Tests\n",
            ">face is NOT a Match (0.782 > 0.500)\n",
            ">face is NOT a Match (0.770 > 0.500)\n",
            "Negative Tests\n",
            ">face is a Match (0.300 <= 0.500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KWkfcdvFkq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d8G2trKFibh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McFp5oTxmv-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90WVOmc-z7cE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7182b6ad-809b-4a0c-b1b9-479ed4a04d29"
      },
      "source": [
        "sharon_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00343823, 0.3260508 , 0.8844234 , ..., 0.1013908 , 0.8112198 ,\n",
              "       0.4408089 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLUGx3gJz7QP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc7bbf9b-e6e3-4c56-b621-cfd10fc7f1c9"
      },
      "source": [
        "len(sharon_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxEjXgu5mSkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLXpv5_qGUou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f1eb1a8b-b18c-4568-e089-ac3cc4aca841"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tf_encrypted as tfe\n",
        "\n",
        "@tfe.local_computation('input-provider')\n",
        "def provide_input():\n",
        "    # normal TensorFlow operations can be run locally\n",
        "    # as part of defining a private input, in this\n",
        "    # case on the machine of the input provider\n",
        "    return tf.ones(shape=(5, 10))\n",
        "\n",
        "# define inputs\n",
        "w = tfe.define_private_variable(tf.ones(shape=(10,10)))\n",
        "print(w)\n",
        "x = provide_input()\n",
        "print(x)\n",
        "\n",
        "# define computation\n",
        "y = tfe.matmul(x, w)\n",
        "print(y)\n",
        "\n",
        "with tfe.Session() as sess:\n",
        "    # initialize variables\n",
        "    sess.run(tfe.global_variables_initializer())\n",
        "    # reveal result\n",
        "    result = sess.run(y.reveal())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PondPrivateVariable(shape=(10, 10))\n",
            "PondPrivateTensor(shape=(5, 10))\n",
            "PondPrivateTensor(shape=(5, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb5wmPKCz6cY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "07efa822-aca3-4cfb-a99b-a23e5c5e732f"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h9A3eiS3sNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "f422a29b-f4e6-4830-e725-898690c870c0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import tf_encrypted as tfe\n",
        "from tf_encrypted.protocol.aby3 import ABY3\n",
        "from tf_encrypted.protocol.aby3 import ARITHMETIC\n",
        "from tf_encrypted.protocol.aby3 import BOOLEAN\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "prot = ABY3()\n",
        "tfe.set_protocol(prot)\n",
        "\n",
        "x = tfe.define_private_variable(tf.ones(shape=(2, 2)))\n",
        "y = tfe.define_private_variable(tf.ones(shape=(2, 2)))\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "\n",
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "with tfe.Session() as sess:\n",
        "    # initialize variables\n",
        "    sess.run(tfe.global_variables_initializer())\n",
        "    # reveal result\n",
        "    result = sess.run(z.reveal())\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-291888e75b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_encrypted\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_encrypted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maby3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mABY3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_encrypted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maby3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mARITHMETIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_encrypted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maby3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBOOLEAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_encrypted.protocol.aby3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI3FYDjg8c8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}